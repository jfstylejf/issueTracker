server.port=8009

baseDir=/app/fudan/codeWisdom

dataBase.ip=10.176.64.34
server.ip=10.176.34.85
#server.ip=127.0.0.1
#数据源
spring.datasource.name=mysql_druid
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.url=jdbc:mysql://${dataBase.ip}:3306/issueTracker?characterEncoding=utf8&useSSL=false&allowMultiQueries=true&autoReconnect=true 
spring.datasource.username=root
spring.datasource.password=HxUR7gT1dLQwPDUwO0SR02gsJj4wxZHbadojloQt4xRPeSLL0FGgn4qwbwC2+/A3YRw3LgrduBjAbey/MJSqjQ==
public-key=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAKG3KtWNiPBAzJQNaG/wnMZpb8gATF2Rr+E84udC2Db35eZEBmD57Hu/3+AHCKY1vw73oDLuve0+u4SKba4M21cCAwEAAQ==
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.druid.filter.config.enabled=true
spring.datasource.druid.connection-properties=config.decrypt=true;config.decrypt.key=${public-key}


#mybatis配置
mybatis.type-aliases-package=cn.edu.fudan.measureservice.domain
mybatis.mapperLocations=classpath:mapper/*.xml

#redis配置

spring.cache.type=redis
#spring.cache.cache-names=portrait
spring.cache.redis.time-to-live=24h
spring.cache.redis.cache-null-values=true
spring.redis.database=6
spring.redis.host=${server.ip}
spring.redis.password=85redis




#kafaka配置
#kafka服务器地址
spring.kafka.bootstrap-servers=${server.ip}:9092
#kafaka消费者配置
# earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
# latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
# none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
spring.kafka.consumer.auto-offset-reset=latest
#每一个Consumer都会属于某个Group,通常一个Group下会有多个Consumer
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.listener.ack-mode=manual_immediate
#max.poll.records默认是500
spring.kafka.consumer.properties.max.poll.records = 250
#session.timeout.ms默认是10000
spring.kafka.consumer.properties.session.timeout.ms = 20000
#max.poll.interval.ms默认是300000
spring.kafka.consumer.properties.max.poll.interval.ms = 600000
#Kafka生产者配置
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.acks=1

spring.jackson.default-property-inclusion=non_null


account.service.path=http://${server.ip}:8001
project.service.path=http://${server.ip}:8002
issue.service.path=http://${server.ip}:8005
repository.service.path=http://${server.ip}:8102/repository
commit.service.path=http://${server.ip}:8102/commit
code.service.path=http://${server.ip}:8102/code-service
uniform.service.path=http://${server.ip}:8000

java.ncss.work.home=${baseDir}/service/measure/javancss/bin/
result.file.home=${baseDir}/service/measure/javancss/result/
bin.home=${baseDir}/bin/
#/home/appuser/fudan/yp/user/issueTracker/repo/gitlab
#repoHome=${baseDir}/repo/
repoHome=${baseDir}/repository/
inactive=2
lessActive=8
relativelyActive=15

token=ec15d79e36e14dd258cfff3d48b73d35
binHome=/home/fdse/codeWisdom/service/measure/bin/
libHome=/home/fdse/codeWisdom/service/measure/lib/
jsResultFileHome=/home/fdse/codeWisdom/service/measure/log/JsResultLog

log4j.rootLogger=DEBUG, stdout, logfile

#mvn clean & mvn package -Dmaven.test.skip=true & scp target\measure-service-0.0.1-SNAPSHOT.jar appuser@10.129.176.50:/app/fudan/codeWisdom/service/measure/ & ssh appuser@10.129.176.50 "/app/fudan/codeWisdom/service/measure/measureService.sh restart"