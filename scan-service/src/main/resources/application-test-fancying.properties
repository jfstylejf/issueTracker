server.port=8003

workHome=/home/fdse/codeWisdom/service/scan
service.ip=http://10.176.34.85
mysql.ip.port=10.176.64.34:3306
kafka.ip.port=127.0.0.1:9092
mvnHome=/usr/local/maven3.5.4
gradlewHome=${workHome}/gradle

# thread pool
dto.pool.size=1
core.pool.size=5
max.pool.size=10
queue.capacity=20
keep.alive.seconds=30
thread.name.prefix=scan-


defaultScanInterval=12
offsetHours=8


account.service.path=${service.ip}:8001
project.service.path=${service.ip}:8002
commit.service.path=${service.ip}:8102/commit
code.service.path=${service.ip}:8102/code-service
repository.service.path=${service.ip}:8102/repository


# tools
issue.service.path=${service.ip}:8005
code-tracker.service.path=${service.ip}:8016
clone.service.path=${service.ip}:8886
measure.service.path=${service.ip}:8008
block.service.path=${service.ip}:8777
dependency.service.path=${service.ip}:8999

# mybatis
mybatis.type-aliases-package=cn.edu.fudan.scanservice.domain
mybatis.mapperLocations=classpath:mapper/*.xml
# http
spring.http.encoding.force=true
spring.http.encoding.charset=UTF-8
spring.http.encoding.enabled=true
# JSON
spring.jackson.date-format=yyyy-MM-dd HH:mm:ss
spring.jackson.time-zone=GMT+8



# mysql
spring.datasource.name=mysql_druid
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.url=jdbc:mysql://${mysql.ip.port}/issueTracker?characterEncoding=utf8&useSSL=false&allowMultiQueries=true&autoReconnect=true
spring.datasource.username=root
spring.datasource.password=HxUR7gT1dLQwPDUwO0SR02gsJj4wxZHbadojloQt4xRPeSLL0FGgn4qwbwC2+/A3YRw3LgrduBjAbey/MJSqjQ==
public-key=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAKG3KtWNiPBAzJQNaG/wnMZpb8gATF2Rr+E84udC2Db35eZEBmD57Hu/3+AHCKY1vw73oDLuve0+u4SKba4M21cCAwEAAQ==
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.druid.filter.config.enabled=true
spring.datasource.druid.connection-properties=config.decrypt=true;config.decrypt.key=${public-key}
spring.datasource.druid.filter.stat.log-slow-sql=true
spring.datasource.druid.filter.stat.slow-sql-millis=3000

#kafka
spring.kafka.bootstrap-servers=${kafka.ip.port}
spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.acks=1

spring.kafka.consumer.properties.max.poll.interval.ms=7200000

logging.level.cn.edu.fudan=debug

test.repo.path=false

# mvn clean package -Dmaven.test.skip=true & scp target/scan-service-0.0.1-SNAPSHOT.jar fdse@10.176.34.85:/home/fdse/codeWisdom/service/scan/ & ssh fdse@10.176.34.85 "/home/fdse/codeWisdom/service/scan/scanService.sh restart"
#  85Cloudfdse1995